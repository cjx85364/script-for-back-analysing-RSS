{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run our back-analyses model, we need to import necessary python module and two .py files, please put the .py file in the same folder of this notebook\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from co_seismic_simulation import co_landslide_strength_inversion # the module to back-analyses for coseismic phase\n",
    "from post_seismic_simulation import po_landslide_strength_inversion # the module to back-analyses for post-seismic phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   peak_ground_acceleration  density  internal_friction_angle  rock_cohesion  \\\n",
      "0                      0.90     26.5                       44             40   \n",
      "1                      0.92     26.5                       44             40   \n",
      "2                      0.86     26.2                       42             39   \n",
      "3                      0.90     26.5                       44             40   \n",
      "4                      0.88     26.5                       44             40   \n",
      "\n",
      "       slope  m_before   m_after  time  \n",
      "0  33.004700         0  0.737017  2011  \n",
      "1  30.135099         0  0.737017  2011  \n",
      "2  40.856998         0  0.804696  2011  \n",
      "3  45.556400         0  0.833959  2011  \n",
      "4  48.797100         0  0.833959  2011  \n"
     ]
    }
   ],
   "source": [
    "# then we input our dataset, each row represent a specific post-seismic landslide location.\n",
    "data=pd.read_csv (\"wenchuan_all_data.csv\",sep=\",\",encoding=\"utf-8\",header=0)\n",
    "# in there, we use first 5 landslides to show a process that using back-analyses model \n",
    "data=data.iloc[:5]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use code below to calculate the shear strenght \n",
    "def calculate_shear_strength(weigth,slope,cohesion,firction,t,m):\n",
    "    normal_stress=(weigth*t-9.8*t*m)*np.cos(slope*np.pi/180.)\n",
    "    shear_strength=normal_stress*np.tan(firction*np.pi/180.)+cohesion\n",
    "    return shear_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the shear strenghth before earthquake\n",
    "# the module has four input parameters: the input data, thickness, cov value for cohesion and cov for friction angle.\n",
    "# In there, we need to assign a cov value for cohesion and friction angle, and also a thickness for landslide\n",
    "# we show a case for thickness equal to 5m where the cov of cohesion is 1.55, cov of friction angle is 0.15\n",
    "# Note the Cohesion1,friction1 is the limit condition result (e.g FS=1) of hillslope stable and failed, which just a try and we don't use in our manuscript \n",
    "# so,the Cohesion1,friction1 is meanless but can't remove because the module need four variables to recieve output. \n",
    "lab=co_landslide_strength_inversion(data,cov_c=1.55,tick=5,cov_i_f=0.15)\n",
    "Cohesion,friction,Cohesion1,friction1=lab.calculate_inversion_strength()# run the model and recieve the output\n",
    "Cohesion[Cohesion< 0] = np.nan #  the model run 1,000 Monte-Carlo simulations,so \"Cohesion\" has 1000 values and we remove the failed one    \n",
    "friction[friction< 0] = np.nan \n",
    "Cohesion=np.nanmean(Cohesion,axis=1)# the final result is the mean of 1,000 simulations (see method in paper).\n",
    "friction=np.nanmean(friction,axis=1)\n",
    "# calculate the shear strength and remeber change t value\n",
    "shear_before=calculate_shear_strength(data[\"density\"],data[\"slope\"],Cohesion,friction,t=5,m=data[\"m_before\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    229.885497\n",
       "1    228.865695\n",
       "2    228.904788\n",
       "3    242.706501\n",
       "4    243.601335\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the shear strength of coseismic phase\n",
    "shear_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the shear strenghth for post-seismic phase \n",
    "# same to above, we need to assign thickness and cov value  \n",
    "lab1=po_landslide_strength_inversion(data,cov_c=1.55,tick=5,cov_i_f=0.15)\n",
    "Cohesion,friction,Cohesion1,friction1=lab1.calculate_inversion_strength()\n",
    "Cohesion[Cohesion < 0] = np.nan\n",
    "friction[friction < 0] = np.nan\n",
    "Cohesion=np.nanmean(Cohesion,axis=1)\n",
    "friction=np.nanmean(friction,axis=1)\n",
    "# remeber change t value and m that represent post-seismic phase, this is a different value with m_before\n",
    "shear_after=calculate_shear_strength(data[\"density\"],data[\"slope\"],Cohesion,friction,t=5,m=data[\"m_after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63.820224\n",
       "1    59.675991\n",
       "2    70.324890\n",
       "3    75.230712\n",
       "4    76.817635\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the shear strength of post-seismic phase\n",
    "shear_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    166.065273\n",
       "1    169.189704\n",
       "2    158.579897\n",
       "3    167.475790\n",
       "4    166.783700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate RSS value \n",
    "reduction_value=shear_before-shear_after\n",
    "reduction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.722383\n",
       "1    0.739253\n",
       "2    0.692777\n",
       "3    0.690034\n",
       "4    0.684658\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate RSS %\n",
    "reduction=reduction_value/shear_before\n",
    "reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output is .csv file\n",
    "output=pd.DataFrame({\"shear_before\":shear_before,\"shear_after\":shear_after,\"reduction\":reduction,\"reduction_value\":reduction_value})\n",
    "output.to_csv('case of back analyses model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
